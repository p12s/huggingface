{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ea5726-5002-4c77-95af-9209411926b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed709ca-ade5-4332-94c8-c2d8e9b09eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1835f3ad791d4f589cb189f5da4807f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada9d900e937478d8d57127d580b664f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c075c4ddd29440692fd970c2514e21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa68f2c57fb241399d418c398487caad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9a4e88b36c40a38b6b3c63272927c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Disable warnings about padding_side that cannot be rectified with current software:\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "model_names = [\"microsoft/DialoGPT-small\", \"microsoft/DialoGPT-medium\", \"microsoft/DialoGPT-large\"]\n",
    "use_model_index = 2  # Change 0: small model, 1: medium, 2: large model (requires most resources!)\n",
    "model_name = model_names[use_model_index]\n",
    "          \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, framework='pt') # , padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344741ae-f4b6-4e8c-a7a8-b3e4f360b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chat function: received a user input and chat-history and returns the model's reply and chat-history:\n",
    "def reply(input_text, history=None):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([history, new_user_input_ids], dim=-1) if history is not None else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    return tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True), chat_history_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b0086-ea96-4ddf-872c-43418bf583a3",
   "metadata": {},
   "source": [
    "> **Note:** while executing a notebook-cell is done with `SHIFT-Enter`, only use `Enter` at the dialog input-prompt `> `, otherwise the notebook seems to hang...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dd5da-73ae-46f5-b4ec-c1abef2c6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please press enter (not SHIFT-enter) after your input:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2263653e28411182a834b8a1e7e4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = None\n",
    "first = True\n",
    "while True:\n",
    "    if first is True:\n",
    "        first = False\n",
    "        print(\"Please press enter (not SHIFT-enter) after your input:\")\n",
    "    input_text = input(\"> \")\n",
    "    if input_text in [\"\", \"bye\", \"quit\", \"exit\"]:\n",
    "        break\n",
    "    reply_text, history_new = reply(input_text, history)\n",
    "    history=history_new\n",
    "    if history.shape[1]>80:\n",
    "        old_shape = history.shape\n",
    "        history = history[:,-80:]\n",
    "        print(f\"History cut from {old_shape} to {history.shape}\")\n",
    "    # history_text = tokenizer.decode(history[0])\n",
    "    # print(f\"Current history: {history_text}\")\n",
    "    print(f\"D_GPT: {reply_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd968e4-a722-45af-888a-79ba4a1e576f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hello' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhello\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hello' is not defined"
     ]
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8400a8-5979-49f1-80bd-814c89f450e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0988d67-a7d0-4f83-b27d-45b1f74dd957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
