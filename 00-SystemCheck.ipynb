{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47040240-fa7e-431b-924f-02ef1696779b",
   "metadata": {},
   "source": [
    "# Installed software check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29867cbd-8ba7-47ce-afd3-c38f5bc1091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.6.0\n",
      "Apple Metal MPS acceleration ok.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(f\"Pytorch version: {torch.__version__}\")\n",
    "    is_torch = True\n",
    "    if torch.backends.mps.is_available() is True:\n",
    "        print(\"Apple Metal MPS acceleration ok.\")\n",
    "    else:\n",
    "        print(\"Your version of Pytorch does not support MPS, Pytorch will be slow.\")\n",
    "except:\n",
    "    print(\"Pytorch is not installed. Please install pytorch!\")\n",
    "    is_torch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f22a840-d023-438d-b5c2-0539d7fe19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLX version: 0.24.0\n",
      "Apple MLX framework is installed ok\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import mlx.core as mx\n",
    "    print(f\"MLX version: {mx.__version__}\")\n",
    "    is_mlx = True\n",
    "    print(\"Apple MLX framework is installed ok\")\n",
    "except:\n",
    "    print(\"MLX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db547c2-4f6f-4016-8719-887a89f3be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensoflow not installed, but it's optional, so this is not a fatal error.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"Tensorflow version: {tf.__version__}\")\n",
    "    is_tensorflow = True\n",
    "    devs=tf.config.list_physical_devices('GPU')\n",
    "    if devs is None or len(devs)==0:\n",
    "        print(\"You have not installed the metal drivers, tensorflow will be slow\")\n",
    "    else:\n",
    "        print(f\"GPU support ok: {devs}\")\n",
    "except:\n",
    "    print(\"Tensoflow not installed, but it's optional, so this is not a fatal error.\")\n",
    "    is_tensorflow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fc1919-f641-4cd0-968a-b7c1738059cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M4 Max\n",
      "\n",
      "systemMemory: 36.00 GB\n",
      "maxCacheSize: 13.50 GB\n",
      "\n",
      "JAX is installed and is using: Metal, ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1742748788.850041  875799 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1742748788.850426  875799 service.cc:145] XLA service 0x135011620 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742748788.850534  875799 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1742748788.851958  875799 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1742748788.851966  875799 mps_client.cc:384] XLA backend will use up to 28989505536 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "    is_jax = True\n",
    "    device_type = jax.devices()[0].device_kind\n",
    "    print(f\"JAX is installed and is using: {device_type}, ok\")\n",
    "except:\n",
    "    print(\"JAX is not installed, it's optional, so this is not a fatal error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf367403-bbcd-4841-a59b-66ead3dd1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace transformers is not installed. This won't work! No module named 'transformers'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import transformers\n",
    "    from transformers import pipeline\n",
    "    print(f\"Transformers version: {transformers.__version__}\")\n",
    "    is_huggingface = True\n",
    "except Exception as e:\n",
    "    print(f\"HuggingFace transformers is not installed. This won't work! {e}\")\n",
    "    is_huggingface = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197a353a-01bb-4ec4-b6be-9bfffda2c568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimal software is not installed. Please check that PyTorch and HuggingFace are installed, following the HowTo!\n",
      "At this stage, non of the examples will work!\n",
      "\n",
      "Hint: all software installed with `pip` needs to be installed into the same active environment,\n",
      "otherwise components won't see each other.\n"
     ]
    }
   ],
   "source": [
    "if is_huggingface is False or is_torch is False:\n",
    "    print(\"The minimal software is not installed. Please check that PyTorch and HuggingFace are installed, following the HowTo!\")\n",
    "    print(\"At this stage, non of the examples will work!\")\n",
    "    print(\"\")\n",
    "    print(\"Hint: all software installed with `pip` needs to be installed into the same active environment,\")\n",
    "    print(\"otherwise components won't see each other.\")\n",
    "else:\n",
    "    print(\"All looks good, let's try a simple sentiment analysis:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3114971-5678-4c9f-8b2e-a618eecc2513",
   "metadata": {},
   "source": [
    "## Sentiment analysis minimal example\n",
    "\n",
    "> **Note:** when this pipeline is run for the first time, several hundred megabytes of models are downloaded once.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07521c38-02bb-4b12-b336-d068ca4d5442",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nlp = \u001b[43mpipeline\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33msentiment-analysis\u001b[39m\u001b[33m\"\u001b[39m, framework=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m nlp(\u001b[33m\"\u001b[39m\u001b[33mWe are very happy to show you the ðŸ¤— Transformers library.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"sentiment-analysis\", framework='pt')\n",
    "nlp(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19962824-6493-4bdd-8446-dc1916720fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.46.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc728f-dc27-49de-bbef-e4b0102cfedd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
